
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Information Extraction from Text &#8212; Data Science in Practice</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Introduction to Features" href="../09/introduction.html" />
    <link rel="prev" title="Text Data" href="patterns.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/toolbox.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science in Practice</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   Data Science in Practice
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Section 1: Understanding Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01/introduction.html">
   1. Introduction to Data Science
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/what-is-data-science.html">
     1.1. What is Data Science?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/scientific-method.html">
     1.2. The Scientific Method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/data-science-example.html">
     1.3. A Data Science Example
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02/introduction.html">
   2. Tabular Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/tabular-data.html">
     2.1. Introduction to Tabular Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/methods.html">
     2.2. DataFrame Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data-types.html">
     2.3. Data Types and Performance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03/introduction.html">
   3. Querying and Describing Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/selecting-data.html">
     3.1. Selecting Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/kinds-of-data.html">
     3.2. Kinds of Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/categorical-distributions.html">
     3.3. Categorical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/quantitative-distributions.html">
     3.4. Quantitative Distributions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04/introduction.html">
   4. Understanding Assumptions and Data Cleaning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modifying-dataframes.html">
     4.1. Modifying DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/cleaning.html">
     4.2. Cleaning Messy Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/eda.html">
     4.3. Exploratory Data Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/asking-questions.html">
     4.4. Hypothesis Testing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../05/introduction.html">
   5. Aggregation and Extension of Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/grouping.html">
     5.1. Data Granularity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/understanding-aggregations.html">
     5.2. Understanding Aggregations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/appending-data.html">
     5.3. Combining Data (Observations)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/joining-data.html">
     5.4. Combining Data (Attributes)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/permutation-tests.html">
     5.5. Permutation Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/eda-2.html">
     5.6. Exploratory Data Analysis II
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../06/introduction.html">
   6. Missing Data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/defining-missing.html">
     6.1. Definitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/identifying-missing.html">
     6.2. Identifying Missing Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/handling-missing-data.html">
     6.3. Handling Missing Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/single-valued-imputation.html">
     6.4. Single-Valued Imputation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/probabilistic-imputation.html">
     6.5. Probabilistic Imputation
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Section 2: Collecting Data
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../07/introduction.html">
   7. Data Collection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/existing-data.html">
     7.1. Using Existing Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/requests.html">
     7.2. HTTP Requests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/html.html">
     7.3. Parsing HTML
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="introduction.html">
   8. Information Extaction
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="patterns.html">
     8.1. Text Processing
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     8.2. Natural Language Processing
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../09/introduction.html">
   9. Introduction to Features
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/features.html">
     9.1. Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/data-pipelines.html">
     9.2. Data Pipelines
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Section 3: Modeling With Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../10/introduction.html">
   10. Modeling Basics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/intro-modeling.html">
     10.1. Introduction to Statistical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/model-building.html">
     10.2. Building Modeling Pipelines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../11/introduction.html">
   11. Bias and Variance
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/fitting-inference.html">
     11.1. Model Quality (Inference)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/fitting-prediction.html">
     11.2. Model Quality (Prediction)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/cross-validation.html">
     11.3. Cross Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/parameter-search.html">
     11.4. Parameter Search
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../12/introduction.html">
   12. Evaluating Models; Fairness
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/eval.html">
     12.1. Evaluation metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/parity.html">
     12.2. Parity Measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/fairness.html">
     12.3. Fairness in Machine Learning
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/08/nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/dsc-courses/ds-in-practice/master?urlpath=tree/book/content/08/nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-limits-of-pattern-matching">
   The Limits of Pattern Matching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-similarity-between-text">
   Measuring Similarity between Text
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-bag-of-words-model">
     The “Bag of Words” model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measures-of-relevancy">
   Measures of Relevancy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency-tf-idf">
     Term Frequency, Inverse Document Frequency (TF-IDF)
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Information Extraction from Text</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-limits-of-pattern-matching">
   The Limits of Pattern Matching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-similarity-between-text">
   Measuring Similarity between Text
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-bag-of-words-model">
     The “Bag of Words” model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measures-of-relevancy">
   Measures of Relevancy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency-tf-idf">
     Term Frequency, Inverse Document Frequency (TF-IDF)
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="information-extraction-from-text">
<h1>Information Extraction from Text<a class="headerlink" href="#information-extraction-from-text" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<div class="section" id="the-limits-of-pattern-matching">
<h2>The Limits of Pattern Matching<a class="headerlink" href="#the-limits-of-pattern-matching" title="Permalink to this headline">¶</a></h2>
<p>Pattern matching is an information extraction on technique on text that offer a way to introduce oneself to raw text. However, pattern matching has its limits:</p>
<ul class="simple">
<li><p>How are common patterns proposed and found?</p></li>
<li><p>The ad-hoc development and exploration of information extraction with patterns does not scale to large amounts of text.</p></li>
<li><p>Assessing the efficacy of a pattern to effectively extract information does not scale well past visual inspection. When an large-scale analysis is done, it’s time consuming and likely not applicable to similar patterns.</p></li>
</ul>
<p>To move beyond these limits, one must approach information extraction from text more methodically, using a quantitative approach borrowed from math and statistics.</p>
</div>
<div class="section" id="measuring-similarity-between-text">
<h2>Measuring Similarity between Text<a class="headerlink" href="#measuring-similarity-between-text" title="Permalink to this headline">¶</a></h2>
<p>Given two snippets of text, are they similar? At heart, this question is asking for <em>a distance measure</em> between words and phrases. While there are many such measures of distance, each capturing different aspects of the information in text, they all require a common setup: how should the text be embedded into a quantitative (e.g. Euclidean) space?</p>
<div class="section" id="the-bag-of-words-model">
<h3>The “Bag of Words” model<a class="headerlink" href="#the-bag-of-words-model" title="Permalink to this headline">¶</a></h3>
<p>Consider the following listings for housing rentals:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>phrase</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>a two bedroom apartment with washer and dryer</p></td>
</tr>
<tr class="row-odd"><td><p>a two bedroom house with a washer hookup</p></td>
</tr>
<tr class="row-even"><td><p>a three bedroom house with a fireplace</p></td>
</tr>
</tbody>
</table>
<p>Since a listing is made up of a collection of amenities, two listings might be considered similar if they share similar words. That is:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">two</span> <span class="pre">bedroom</span> <span class="pre">apartment</span> <span class="pre">with</span> <span class="pre">washer</span> <span class="pre">and</span> <span class="pre">dryer</span></code> and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">two</span> <span class="pre">bedroom</span> <span class="pre">house</span> <span class="pre">with</span> <span class="pre">a</span> <span class="pre">washer</span> <span class="pre">hookup</span></code></p></li>
</ul>
<p>share five words (<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">two</span></code>, <code class="docutils literal notranslate"><span class="pre">bedroom</span></code>, <code class="docutils literal notranslate"><span class="pre">with</span></code>, <code class="docutils literal notranslate"><span class="pre">washer</span></code>). This matching can be turned into a measure of similarity in a number of ways:</p>
<ul class="simple">
<li><p>Using the raw number itself as a measure, where larger is more similar (e.g. the similarity is 5).</p></li>
<li><p>Using the proportion of possible matches, where 1 is the most similar (e.g. 5/7 words were matches).</p></li>
<li><p>Computing the empirical distribution of each phrase and using the Total Variation Distance (TVD).</p></li>
</ul>
<p><em>Remark:</em> The first measure is not normalized, which is may be a good property. The likelihood that two very long phrases are similar is much smaller than two short phrases.</p>
<p>The ‘Bag of Words’ model sets up this notion of similarity by embedding the words into a <em>vector space</em>. This vector space embedding allows one to easily compute different notions of similar and understand the distribution of words among the phrases in a dataset.</p>
<p>The <strong>Bag of Words embedding</strong> of a list of phrases is representation of the counts of words in each phrase in vector space whose basis consists of all words appearing in the dataset.</p>
<p><strong>Example:</strong> The Bag of Words embedding of the three row table of housing listings transforms the phrases into a 12-dimensional vector space:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>a</p></th>
<th class="head"><p>two</p></th>
<th class="head"><p>three</p></th>
<th class="head"><p>bedroom</p></th>
<th class="head"><p>apartment</p></th>
<th class="head"><p>house</p></th>
<th class="head"><p>with</p></th>
<th class="head"><p>washer</p></th>
<th class="head"><p>hookup</p></th>
<th class="head"><p>and</p></th>
<th class="head"><p>dryer</p></th>
<th class="head"><p>fireplace</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p><em>Remark:</em> Notice that the bag-of-words embedding is nothing but systematically pattern matching: for each word in the dataset, count the number of occurrences of each words in each phrase. However, the Bag of Words embedding doesn’t know anything about the <em>meaning</em> of each words. The embedding works under the assumption that two phrases are similar if they share many of the same words.</p>
<p>Using a Bag of Words embedding, the <strong>similarity</strong> of two phrases can be measured using notions of similarity in the Bag of Words vector space. Under the Bag of Word embedding:</p>
<ul class="simple">
<li><p>The similarity of two phrases is proportional to the dot product of the Bag of Words vectors.</p></li>
<li><p>The similarity of two phrases is given by the <em>cosine similarity</em> of the Bag of Words vectors:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[dist(v, w) = 1 - \cos(\theta) = 1 - \frac{v \cdot w}{|v||w|}\]</div>
<p><strong>Example:</strong> In the above housing listings, which listings are most similar under the Bag of Words model?</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>phrase pair</p></th>
<th class="head"><p>dot product</p></th>
<th class="head"><p>cosine similarity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0,1</p></td>
<td><p>2+1+0+1+0+0+1+1+0+0+0+0 = 6</p></td>
<td><p>0.33</p></td>
</tr>
<tr class="row-odd"><td><p>0,2</p></td>
<td><p>2+0+0+1+0+1+1+0+0+0+0+0 = 5</p></td>
<td><p>0.41</p></td>
</tr>
<tr class="row-even"><td><p>1,2</p></td>
<td><p>4+0+0+1+0+1+1+0+0+0+0+0 = 7</p></td>
<td><p>0.26</p></td>
</tr>
</tbody>
</table>
<p>As measured by the cosine similarity, the most similar phrase pair is the middle and last phrases.</p>
<p><em>Remark:</em> The Bag of Words model has downsides, already seen in this example:</p>
<ul class="simple">
<li><p>The model treats all words as <em>equally important</em>. For exaample, the word ‘a’ and the word ‘apartment’ are given equal weight.</p></li>
<li><p>The model treats words without context. The phrases ‘I own a dog’ and ‘I don’t own a dog’ are similar in the bag of words model.</p></li>
</ul>
<p>However, the perspective of the Bag of Words model is powerful. These downsides can be handled with straightforward improvements and modifications.</p>
</div>
</div>
<div class="section" id="measures-of-relevancy">
<h2>Measures of Relevancy<a class="headerlink" href="#measures-of-relevancy" title="Permalink to this headline">¶</a></h2>
<p>A shortcoming of the naive Bag of Words model is that it treats every words equally. This treatment can cause two phrases with similar content to appear dissimilar because of ‘superfluous’ words. What are ways to extract ‘the most relevant’ words from a phrase?</p>
<div class="section" id="term-frequency-inverse-document-frequency-tf-idf">
<h3>Term Frequency, Inverse Document Frequency (TF-IDF)<a class="headerlink" href="#term-frequency-inverse-document-frequency-tf-idf" title="Permalink to this headline">¶</a></h3>
<p>An intuitive heuristic for extracting the most relevant term of a phrase is <em>Term Frequency, Inverse Document Frequency</em> or TF-IDF. This method attempts to answer the question “how much does a given word summarize a phrase?”.  TF-IDF attempts to balance the importance of a word in a given document with the uniqueness the word has to the document.</p>
<p>Suppose a dataset consists of a <em>collection of documents</em> <span class="math notranslate nohighlight">\(D\)</span>.</p>
<ul class="simple">
<li><p>The <em>term frequency</em> of a word <span class="math notranslate nohighlight">\(t\)</span> in a document <span class="math notranslate nohighlight">\(d\)</span>, denoted <span class="math notranslate nohighlight">\({\rm tf}(t,d)\)</span>, is the likelihood of the term appearing in the document:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\rm tf}(t, d) = \frac{\rm{number\: of\: times\: t\: appears\: in\: document\: d}}{\rm{total\: number\: of\: terms\: in\: document\: d}} \]</div>
<ul class="simple">
<li><p>The <em>inverse document frequency</em> of a word <span class="math notranslate nohighlight">\(t\)</span> in a collection of documents <span class="math notranslate nohighlight">\(D\)</span>, denoted <span class="math notranslate nohighlight">\({\rm idf}(t,d)\)</span> is:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\rm idf}(t) = \log\left(\frac{\rm{total\: number\: of\: documents}}{\rm{number\: of\: documents\: in\: which\: t\: appears}}\right)\]</div>
<ul class="simple">
<li><p>The <em>tf-idf</em> of a term <span class="math notranslate nohighlight">\(t\)</span> in document <span class="math notranslate nohighlight">\(d\)</span> is given by the product:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\rm tfidf}(t,d) = {\rm tf}(t,d) \cdot {\rm idf}(t)\]</div>
<p><em>Remark:</em> There are different, related, ways of computing this quantity. As this method is a heuristic, there isn’t a ‘correct’ formula with a probabilistic interpretation.</p>
<p>Notice that if a term appears in <em>every</em> document in the collection, the <span class="math notranslate nohighlight">\({\rm idf(t, d)}\)</span> is zero. This fits the intuition that very common words should not be considered relevant to the information contained in a document.</p>
<p><strong>Example:</strong> The TF-IDF of the word <code class="docutils literal notranslate"><span class="pre">two</span></code> in the first apartment listing is computed as follows:</p>
<div class="math notranslate nohighlight">
\[{\rm tf}(\texttt{two}, \texttt{listing0}) = \frac{1}{8}\]</div>
<div class="math notranslate nohighlight">
\[{\rm idf}(\texttt{two}) = \log(\frac{3}{2})\]</div>
<div class="math notranslate nohighlight">
\[{\rm tf}(\texttt{two}, \texttt{listing0})\cdot {\rm idf}(\texttt{two}) = \frac{1}{8}\log(\frac{3}{2})\]</div>
<p>This quantity naturally defines the most relevant words for a given document: the term with the highest TF-IDF for a given document <em>best summarizes</em> the document.</p>
<p><strong>Example:</strong> Computing the most relevant term for each listing is illustrated in the following code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">apts</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phrase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a two bedroom apartment with washer and dryer</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a two bedroom house with a washer hookup</td>
    </tr>
    <tr>
      <th>2</th>
      <td>a three bedroom house with a fireplace</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>While slower than leveraging optimized libraries, the Bag of Words embedding can be easily implemented with Pandas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">apts</span><span class="p">[</span><span class="s1">&#39;phrase&#39;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="p">)</span>
<span class="n">bow</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>washer</th>
      <th>with</th>
      <th>apartment</th>
      <th>two</th>
      <th>a</th>
      <th>and</th>
      <th>dryer</th>
      <th>bedroom</th>
      <th>hookup</th>
      <th>house</th>
      <th>three</th>
      <th>fireplace</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The term frequencies of each word, in each document, is represented in a matrix labeled by words and document number. Each word in a given document is part of an empirical distribution for that document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">term_frequencies</span> <span class="o">=</span> <span class="n">bow</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">term_frequencies</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>washer</th>
      <th>with</th>
      <th>apartment</th>
      <th>two</th>
      <th>a</th>
      <th>and</th>
      <th>dryer</th>
      <th>bedroom</th>
      <th>hookup</th>
      <th>house</th>
      <th>three</th>
      <th>fireplace</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.125</td>
      <td>0.125000</td>
      <td>0.125</td>
      <td>0.125</td>
      <td>0.125000</td>
      <td>0.125</td>
      <td>0.125</td>
      <td>0.125000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.125</td>
      <td>0.125000</td>
      <td>NaN</td>
      <td>0.125</td>
      <td>0.250000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.125000</td>
      <td>0.125</td>
      <td>0.125000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>0.142857</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.285714</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.142857</td>
      <td>NaN</td>
      <td>0.142857</td>
      <td>0.142857</td>
      <td>0.142857</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The inverse document frequency is calculated using a straightforward count of non-null entries:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tot</span> <span class="o">=</span> <span class="n">bow</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">inverse_document_frequencies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tot</span> <span class="o">/</span> <span class="n">bow</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">inverse_document_frequencies</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>washer       0.405465
with         0.000000
apartment    1.098612
               ...   
house        0.405465
three        1.098612
fireplace    1.098612
Length: 12, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The resulting tfidf matrix represents the term frequency, inverse document of frequency of every term in every document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf</span> <span class="o">=</span> <span class="n">term_frequencies</span> <span class="o">*</span> <span class="n">inverse_document_frequencies</span>
<span class="n">tfidf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>washer</th>
      <th>with</th>
      <th>apartment</th>
      <th>two</th>
      <th>a</th>
      <th>and</th>
      <th>dryer</th>
      <th>bedroom</th>
      <th>hookup</th>
      <th>house</th>
      <th>three</th>
      <th>fireplace</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.050683</td>
      <td>0.0</td>
      <td>0.137327</td>
      <td>0.050683</td>
      <td>0.0</td>
      <td>0.137327</td>
      <td>0.137327</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.050683</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.050683</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.137327</td>
      <td>0.050683</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.057924</td>
      <td>0.156945</td>
      <td>0.156945</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The most relevant word in each document corresponds to the word with the largest tfidf in that document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    apartment
1       hookup
2        three
dtype: object
</pre></div>
</div>
</div>
</div>
<p><em>Remark:</em> Why are these words good summaries of each listing? In what ways are they <em>not</em> good summaries?</p>
<p><em>Remark:</em> These words were not the only correct answers; search for ties in the table.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/08"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="patterns.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Text Data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../09/introduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Features</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Aaron Fraenkel<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>